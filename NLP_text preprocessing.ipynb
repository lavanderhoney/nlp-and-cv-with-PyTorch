{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Text preprocessing\n",
        "\n",
        "Steps involved in preprocessing:\n",
        "\n",
        "1. Noise removal/text cleaning:\n",
        "   a. Converting to lowercase\n",
        "   b. Removing punctuation\n",
        "\n",
        "2. Tokenization: break the large string into smaller manageable strings (i.e., words)\n",
        "\n",
        "3. Stopword removal: remove most common words from the tokenized data (like prepositions, articles)\n",
        "\n",
        "4. Text normalization:\n",
        "   a. Stemming: removing the suffixes of the words\n",
        "   b. Lemmatization: reducing the words to their root form\n"
      ],
      "metadata": {
        "id": "VCRuZwGSsGA6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2: NLP Libraries\n",
        "\n",
        "- **nltk (Natural Language Toolkit)**: General purpose comprehensive NLP library. It has libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning of text. It can be used for educational purposes, research, and prototyping of NLP tasks.\n",
        "\n",
        "- **spaCy**: Industrial grade NLP library for advanced NLP tasks. It is efficient for large-scale information extraction tasks. It includes tokenization, part-of-speech tagging, named entity recognition, and dependency parsing.\n",
        "\n",
        "- **wordcloud**: Generates word cloud, where the size of a word in the diagram is proportional to its frequency in the text.\n",
        "\n",
        "- **pyspellchecker**: Used to correct misspelled words, using Levenshtein Distance algorithm.\n",
        "\n",
        "- **gensim**: Library for topic modelling, document indexing and similarity retrieval. It implements algorithms like Word2Vec, FastText, and Latent Dirichlet Allocation (LDA)."
      ],
      "metadata": {
        "id": "_hx6xj29sImN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHKEarlklTvm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNlwY6Bmn7iL",
        "outputId": "c8ecfbaa-5056-454e-be13-abf1d2964303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"\"\" THE BOY’S NAME WAS SANTIAGO. DUSK WAS FALLING AS the boy arrived\n",
        "with his herd at an abandoned church. The roof had fallen in long\n",
        "ago, and an enormous sycamore had grown on the spot where the\n",
        "sacristy had once stood.\n",
        "He decided to spend the night there. He saw to it that all the\n",
        "sheep entered through the ruined gate, and then laid some planks\n",
        "across it to prevent the flock from wandering away during the night.\n",
        "There were no wolves in the region, but once an animal had strayed\n",
        "during the night, and the boy had had to spend the entire next day\n",
        "searching for it.\n",
        "He swept the floor with his jacket and lay down, using the book\n",
        "he had just finished reading as a pillow. He told himself that he\n",
        "would have to start reading thicker books: they lasted longer, and\n",
        "made more comfortable pillows.\n",
        "It was still dark when he awoke, and, looking up, he could see\n",
        "the stars through the half-destroyed roof.\n",
        "I wanted to sleep a little longer, he thought. He had had the same\n",
        "dream that night as a week ago, and once again he had awakened\n",
        "before it ended.\n",
        "He arose and, taking up his crook, began to awaken the sheep\n",
        "that still slept. He had noticed that, as soon as he awoke, most of his\n",
        "animals also began to stir. It was as if some mysterious energy\n",
        "bound his life to that of the sheep, with whom he had spent the past\n",
        "two years, leading them through the countryside in search of food\n",
        "and water. “They are so used to me that they know my schedule,” he\n",
        "muttered. Thinking about that for a moment, he realized that it\n",
        "could be the other way around: that it was he who had become\n",
        "accustomed to their schedule.\"\"\""
      ],
      "metadata": {
        "id": "9QsEq9TKlsYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise Removal and Tokenization"
      ],
      "metadata": {
        "id": "q_GpjLqXw_EA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting to lowercase and removing whitespaces\n",
        "text = text.lower().strip()\n",
        "\n",
        "#Removing punctuation\n",
        "punction = string.punctuation\n",
        "mapping = str.maketrans(\"\",\"\",punction)\n",
        "\n",
        "text = text.translate(mapping)\n",
        "\n",
        "stopwords_eng = stopwords.words('english')\n",
        "\n",
        "def remove_stopwords(in_str):\n",
        "    new_str = ''\n",
        "    words = in_str.split()\n",
        "    for word in words:\n",
        "        if word not in stopwords_eng:\n",
        "            new_str = new_str + word + \" \"\n",
        "\n",
        "    return new_str\n",
        "\n",
        "text_res = remove_stopwords(text)\n",
        "print(text_res)\n",
        "\n",
        "#tokenization\n",
        "tokens = word_tokenize(text_res)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZLWjEzbmEEW",
        "outputId": "8f4c7f9a-b0ea-436e-bbf8-be9cce94649e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "boy’s name santiago dusk falling boy arrived herd abandoned church roof fallen long ago enormous sycamore grown spot sacristy stood decided spend night saw sheep entered ruined gate laid planks across prevent flock wandering away night wolves region animal strayed night boy spend entire next day searching swept floor jacket lay using book finished reading pillow told would start reading thicker books lasted longer made comfortable pillows still dark awoke looking could see stars halfdestroyed roof wanted sleep little longer thought dream night week ago awakened ended arose taking crook began awaken sheep still slept noticed soon awoke animals also began stir mysterious energy bound life sheep spent past two years leading countryside search food water “they used know schedule” muttered thinking moment realized could way around become accustomed schedule \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing most common words"
      ],
      "metadata": {
        "id": "r4O-3wG5xCxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "counter=Counter()\n",
        "\n",
        "#Count frequency of every word\n",
        "for word in tokens:\n",
        "  counter[word]+=1\n",
        "\n",
        "most_freq=counter.most_common(25)\n",
        "print(counter)\n",
        "\n",
        "most_freq_words=[]\n",
        "for word, freq in most_freq:\n",
        "    most_freq_words.append(word)\n",
        "\n",
        "def remove_frequent(tokens):\n",
        "    new_tokens = []\n",
        "    for word in tokens:\n",
        "        if word not in most_freq_words:\n",
        "            new_tokens.append(word)\n",
        "    return new_tokens\n",
        "\n",
        "tokens_removed_cmn = remove_frequent(tokens)\n",
        "print(\"Tokens most common removed: \",tokens_removed_cmn)\n",
        "\n",
        "# most_rare = counter.most_common(-25)\n",
        "# print(\"rare: \",most_rare)\n",
        "# most_rare_words = []\n",
        "# for word,freq in most_rare:\n",
        "#   most_rare_words.append(word)\n",
        "# print(most_rare_words)\n",
        "\n",
        "# tokens_removed_rare = remove_frequent(tokens)\n",
        "# tokens_processed = remove_frequent(tokens_removed_cmn)\n",
        "# print(tokens_processed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4e_m7sItE0t",
        "outputId": "87ee3572-aa5a-433a-a7da-f6155f58dd6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({'night': 4, 'boy': 3, 'sheep': 3, 'roof': 2, 'ago': 2, 'spend': 2, 'reading': 2, 'longer': 2, 'still': 2, 'awoke': 2, 'could': 2, 'began': 2, 'schedule': 2, '’': 1, 's': 1, 'name': 1, 'santiago': 1, 'dusk': 1, 'falling': 1, 'arrived': 1, 'herd': 1, 'abandoned': 1, 'church': 1, 'fallen': 1, 'long': 1, 'enormous': 1, 'sycamore': 1, 'grown': 1, 'spot': 1, 'sacristy': 1, 'stood': 1, 'decided': 1, 'saw': 1, 'entered': 1, 'ruined': 1, 'gate': 1, 'laid': 1, 'planks': 1, 'across': 1, 'prevent': 1, 'flock': 1, 'wandering': 1, 'away': 1, 'wolves': 1, 'region': 1, 'animal': 1, 'strayed': 1, 'entire': 1, 'next': 1, 'day': 1, 'searching': 1, 'swept': 1, 'floor': 1, 'jacket': 1, 'lay': 1, 'using': 1, 'book': 1, 'finished': 1, 'pillow': 1, 'told': 1, 'would': 1, 'start': 1, 'thicker': 1, 'books': 1, 'lasted': 1, 'made': 1, 'comfortable': 1, 'pillows': 1, 'dark': 1, 'looking': 1, 'see': 1, 'stars': 1, 'halfdestroyed': 1, 'wanted': 1, 'sleep': 1, 'little': 1, 'thought': 1, 'dream': 1, 'week': 1, 'awakened': 1, 'ended': 1, 'arose': 1, 'taking': 1, 'crook': 1, 'awaken': 1, 'slept': 1, 'noticed': 1, 'soon': 1, 'animals': 1, 'also': 1, 'stir': 1, 'mysterious': 1, 'energy': 1, 'bound': 1, 'life': 1, 'spent': 1, 'past': 1, 'two': 1, 'years': 1, 'leading': 1, 'countryside': 1, 'search': 1, 'food': 1, 'water': 1, '“': 1, 'they': 1, 'used': 1, 'know': 1, '”': 1, 'muttered': 1, 'thinking': 1, 'moment': 1, 'realized': 1, 'way': 1, 'around': 1, 'become': 1, 'accustomed': 1})\n",
            "Tokens most common removed:  ['enormous', 'sycamore', 'grown', 'spot', 'sacristy', 'stood', 'decided', 'saw', 'entered', 'ruined', 'gate', 'laid', 'planks', 'across', 'prevent', 'flock', 'wandering', 'away', 'wolves', 'region', 'animal', 'strayed', 'entire', 'next', 'day', 'searching', 'swept', 'floor', 'jacket', 'lay', 'using', 'book', 'finished', 'pillow', 'told', 'would', 'start', 'thicker', 'books', 'lasted', 'made', 'comfortable', 'pillows', 'dark', 'looking', 'see', 'stars', 'halfdestroyed', 'wanted', 'sleep', 'little', 'thought', 'dream', 'week', 'awakened', 'ended', 'arose', 'taking', 'crook', 'awaken', 'slept', 'noticed', 'soon', 'animals', 'also', 'stir', 'mysterious', 'energy', 'bound', 'life', 'spent', 'past', 'two', 'years', 'leading', 'countryside', 'search', 'food', 'water', '“', 'they', 'used', 'know', '”', 'muttered', 'thinking', 'moment', 'realized', 'way', 'around', 'become', 'accustomed']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Normalization: Stemming and Lemmatization"
      ],
      "metadata": {
        "id": "oeWSqtnGxQ9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_text =[]\n",
        "stemmer= PorterStemmer()\n",
        "# stemmer = LancasterStemmer() Lancaster has more rules than Porter\n",
        "for word in tokens_removed_cmn:\n",
        "  stemmed_text.append(stemmer.stem(word))\n",
        "\n",
        "print(\"Stemmed text: \")\n",
        "for w in stemmed_text:\n",
        "  print(w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdBL5-lCtMX9",
        "outputId": "46d782a3-89fe-42c3-f25f-edb78a08a219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stemmed text: \n",
            "enorm\n",
            "sycamor\n",
            "grown\n",
            "spot\n",
            "sacristi\n",
            "stood\n",
            "decid\n",
            "saw\n",
            "enter\n",
            "ruin\n",
            "gate\n",
            "laid\n",
            "plank\n",
            "across\n",
            "prevent\n",
            "flock\n",
            "wander\n",
            "away\n",
            "wolv\n",
            "region\n",
            "anim\n",
            "stray\n",
            "entir\n",
            "next\n",
            "day\n",
            "search\n",
            "swept\n",
            "floor\n",
            "jacket\n",
            "lay\n",
            "use\n",
            "book\n",
            "finish\n",
            "pillow\n",
            "told\n",
            "would\n",
            "start\n",
            "thicker\n",
            "book\n",
            "last\n",
            "made\n",
            "comfort\n",
            "pillow\n",
            "dark\n",
            "look\n",
            "see\n",
            "star\n",
            "halfdestroy\n",
            "want\n",
            "sleep\n",
            "littl\n",
            "thought\n",
            "dream\n",
            "week\n",
            "awaken\n",
            "end\n",
            "aros\n",
            "take\n",
            "crook\n",
            "awaken\n",
            "slept\n",
            "notic\n",
            "soon\n",
            "anim\n",
            "also\n",
            "stir\n",
            "mysteri\n",
            "energi\n",
            "bound\n",
            "life\n",
            "spent\n",
            "past\n",
            "two\n",
            "year\n",
            "lead\n",
            "countrysid\n",
            "search\n",
            "food\n",
            "water\n",
            "“\n",
            "they\n",
            "use\n",
            "know\n",
            "”\n",
            "mutter\n",
            "think\n",
            "moment\n",
            "realiz\n",
            "way\n",
            "around\n",
            "becom\n",
            "accustom\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_text =[]\n",
        "for word in tokens_removed_cmn:\n",
        "  lemmatized_text.append(lemmatizer.lemmatize(word))\n",
        "\n",
        "print(\"Lemmatized text: \")\n",
        "for w in lemmatized_text:\n",
        "  print(w)"
      ],
      "metadata": {
        "id": "VuhyKcYxwqRi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0ee6b2-f279-44de-e9e0-378cc253a6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lemmatized text: \n",
            "enormous\n",
            "sycamore\n",
            "grown\n",
            "spot\n",
            "sacristy\n",
            "stood\n",
            "decided\n",
            "saw\n",
            "entered\n",
            "ruined\n",
            "gate\n",
            "laid\n",
            "plank\n",
            "across\n",
            "prevent\n",
            "flock\n",
            "wandering\n",
            "away\n",
            "wolf\n",
            "region\n",
            "animal\n",
            "strayed\n",
            "entire\n",
            "next\n",
            "day\n",
            "searching\n",
            "swept\n",
            "floor\n",
            "jacket\n",
            "lay\n",
            "using\n",
            "book\n",
            "finished\n",
            "pillow\n",
            "told\n",
            "would\n",
            "start\n",
            "thicker\n",
            "book\n",
            "lasted\n",
            "made\n",
            "comfortable\n",
            "pillow\n",
            "dark\n",
            "looking\n",
            "see\n",
            "star\n",
            "halfdestroyed\n",
            "wanted\n",
            "sleep\n",
            "little\n",
            "thought\n",
            "dream\n",
            "week\n",
            "awakened\n",
            "ended\n",
            "arose\n",
            "taking\n",
            "crook\n",
            "awaken\n",
            "slept\n",
            "noticed\n",
            "soon\n",
            "animal\n",
            "also\n",
            "stir\n",
            "mysterious\n",
            "energy\n",
            "bound\n",
            "life\n",
            "spent\n",
            "past\n",
            "two\n",
            "year\n",
            "leading\n",
            "countryside\n",
            "search\n",
            "food\n",
            "water\n",
            "“\n",
            "they\n",
            "used\n",
            "know\n",
            "”\n",
            "muttered\n",
            "thinking\n",
            "moment\n",
            "realized\n",
            "way\n",
            "around\n",
            "become\n",
            "accustomed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Part of speech tagging, for eg: JJ: noun, IN: preposition, VBG: verb,gerund or present participles, RB: adverb\n",
        "nltk.pos_tag(tokens_removed_cmn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j07EYpiqzP3O",
        "outputId": "1aff39fa-36a2-425a-fb5c-9aea232d940e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('enormous', 'JJ'),\n",
              " ('sycamore', 'NN'),\n",
              " ('grown', 'JJ'),\n",
              " ('spot', 'NN'),\n",
              " ('sacristy', 'JJ'),\n",
              " ('stood', 'NN'),\n",
              " ('decided', 'VBD'),\n",
              " ('saw', 'NN'),\n",
              " ('entered', 'VBD'),\n",
              " ('ruined', 'JJ'),\n",
              " ('gate', 'NN'),\n",
              " ('laid', 'VBD'),\n",
              " ('planks', 'NNS'),\n",
              " ('across', 'IN'),\n",
              " ('prevent', 'NN'),\n",
              " ('flock', 'NN'),\n",
              " ('wandering', 'VBG'),\n",
              " ('away', 'RB'),\n",
              " ('wolves', 'VBZ'),\n",
              " ('region', 'NN'),\n",
              " ('animal', 'JJ'),\n",
              " ('strayed', 'VBN'),\n",
              " ('entire', 'JJ'),\n",
              " ('next', 'JJ'),\n",
              " ('day', 'NN'),\n",
              " ('searching', 'VBG'),\n",
              " ('swept', 'JJ'),\n",
              " ('floor', 'NN'),\n",
              " ('jacket', 'NN'),\n",
              " ('lay', 'VBD'),\n",
              " ('using', 'VBG'),\n",
              " ('book', 'NN'),\n",
              " ('finished', 'VBD'),\n",
              " ('pillow', 'JJ'),\n",
              " ('told', 'RB'),\n",
              " ('would', 'MD'),\n",
              " ('start', 'VB'),\n",
              " ('thicker', 'NN'),\n",
              " ('books', 'NNS'),\n",
              " ('lasted', 'VBD'),\n",
              " ('made', 'VBN'),\n",
              " ('comfortable', 'JJ'),\n",
              " ('pillows', 'NNS'),\n",
              " ('dark', 'VBP'),\n",
              " ('looking', 'VBG'),\n",
              " ('see', 'NN'),\n",
              " ('stars', 'NNS'),\n",
              " ('halfdestroyed', 'VBD'),\n",
              " ('wanted', 'JJ'),\n",
              " ('sleep', 'JJ'),\n",
              " ('little', 'JJ'),\n",
              " ('thought', 'JJ'),\n",
              " ('dream', 'NN'),\n",
              " ('week', 'NN'),\n",
              " ('awakened', 'VBD'),\n",
              " ('ended', 'VBN'),\n",
              " ('arose', 'RB'),\n",
              " ('taking', 'VBG'),\n",
              " ('crook', 'NN'),\n",
              " ('awaken', 'VBN'),\n",
              " ('slept', 'NN'),\n",
              " ('noticed', 'VBN'),\n",
              " ('soon', 'RB'),\n",
              " ('animals', 'NNS'),\n",
              " ('also', 'RB'),\n",
              " ('stir', 'VBP'),\n",
              " ('mysterious', 'JJ'),\n",
              " ('energy', 'NN'),\n",
              " ('bound', 'IN'),\n",
              " ('life', 'NN'),\n",
              " ('spent', 'VBN'),\n",
              " ('past', 'IN'),\n",
              " ('two', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('leading', 'VBG'),\n",
              " ('countryside', 'NN'),\n",
              " ('search', 'NN'),\n",
              " ('food', 'NN'),\n",
              " ('water', 'NN'),\n",
              " ('“', 'NN'),\n",
              " ('they', 'PRP'),\n",
              " ('used', 'VBD'),\n",
              " ('know', 'VBP'),\n",
              " ('”', 'RB'),\n",
              " ('muttered', 'VBN'),\n",
              " ('thinking', 'VBG'),\n",
              " ('moment', 'NN'),\n",
              " ('realized', 'VBN'),\n",
              " ('way', 'NN'),\n",
              " ('around', 'IN'),\n",
              " ('become', 'NN'),\n",
              " ('accustomed', 'VBD')]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}